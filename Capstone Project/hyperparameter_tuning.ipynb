{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter Tuning using HyperDrive\n",
        "\n",
        "TODO: Import Dependencies. In the cell below, import all the dependencies that you will need to complete the project."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Import all needed Python modules\n",
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import dates\n",
        "\n",
        "import azureml.core\n",
        "from azureml.core.experiment import Experiment\n",
        "from azureml.core.workspace import Workspace\n",
        "from azureml.core.dataset import Dataset\n",
        "from azureml.core.environment import Environment\n",
        "from azureml.data.dataset_factory import TabularDatasetFactory\n",
        "from azureml.core.compute import ComputeTarget\n",
        "from azureml.widgets import RunDetails\n",
        "from azureml.core.runconfig import DockerConfiguration\n",
        "from azureml.core import ScriptRunConfig\n",
        "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
        "from azureml.train.hyperdrive.sampling import BayesianParameterSampling\n",
        "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
        "from azureml.train.hyperdrive.parameter_expressions import uniform, choice\n",
        "\n",
        "# Check core SDK version number\n",
        "print(\"SDK version:\", azureml.core.VERSION)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SDK version: 1.31.0\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1628787237145
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "TODO: Get data. In the cell below, write code to access the data you will be using in this project. Remember that the dataset needs to be external."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Use current workspace \n",
        "ws = Workspace.from_config()\n",
        "\n",
        "# Use default datastore\n",
        "datastore = ws.get_default_datastore()\n",
        "\n",
        "# Choose a name for experiment  \n",
        "experiment_name = 'capstone-project'\n",
        "experiment=Experiment(ws, experiment_name)\n",
        "\n",
        "# Choose a name for your CPU cluster\n",
        "# If the cluster exists, use it. Otherwise create it\n",
        "amlcompute_cluster_name = 'capstone-compute'\n",
        "compute_target = ComputeTarget(workspace=ws, name=amlcompute_cluster_name)"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1628787238424
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile conda_dependencies.yml\n",
        "\n",
        "channels:\n",
        "- conda-forge\n",
        "dependencies:\n",
        "- python=3.7\n",
        "- pip:\n",
        "  - matplotlib\n",
        "  - joblib\n",
        "  - psutil==5.8.0\n",
        "  - tqdm==4.59.0\n",
        "  - pandas==1.1.5\n",
        "  - scipy==1.5.4\n",
        "  - numpy==1.16.0\n",
        "  - azureml-core==1.30.0\n",
        "  - azureml-defaults==1.30.0\n",
        "  - azureml-telemetry==1.30.0\n",
        "  - tensorboard==2.4.0\n",
        "  - tensorflow-gpu==2.4.1\n",
        "  - horovod[tensorflow-gpu]==0.21.3\n",
        "  - scikit-learn==0.24.0"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting conda_dependencies.yml\n"
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1628776510381
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile dockerfile\n",
        "\n",
        "FROM mcr.microsoft.com/azureml/openmpi4.1.0-cuda11.0.3-cudnn8-ubuntu18.04:20210615.v1\n",
        "\n",
        "ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/tensorflow-2.4\n",
        "\n",
        "# Create conda environment\n",
        "RUN conda create -p $AZUREML_CONDA_ENVIRONMENT_PATH \\\n",
        "    python=3.7 pip=20.2.4\n",
        "\n",
        "# Prepend path to AzureML conda environment\n",
        "ENV PATH $AZUREML_CONDA_ENVIRONMENT_PATH/bin:$PATH\n",
        "\n",
        "# Install pip dependencies\n",
        "RUN HOROVOD_WITH_TENSORFLOW=1 \\\n",
        "    pip install 'matplotlib>=3.3,<3.4' \\\n",
        "                'psutil>=5.8,<5.9' \\\n",
        "                'tqdm>=4.59,<4.60' \\\n",
        "                'pandas>=1.1,<1.2' \\\n",
        "                'scipy>=1.5,<1.6' \\\n",
        "                'numpy>=1.10,<1.20' \\\n",
        "                'azureml-core==1.30.0' \\\n",
        "                'azureml-defaults==1.30.0' \\\n",
        "                'azureml-telemetry==1.30.0' \\\n",
        "                'tensorboard==2.4.0' \\\n",
        "                'tensorflow-gpu==2.4.1' \\\n",
        "                'horovod[tensorflow-gpu]==0.21.3' \\\n",
        "                'scikit-learn==0.24.0'\n",
        "\n",
        "# This is needed for mpi to locate libpython\n",
        "ENV LD_LIBRARY_PATH $AZUREML_CONDA_ENVIRONMENT_PATH/lib:$LD_LIBRARY_PATH"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting dockerfile\n"
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628782040911
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # If you used the conda file created above...\n",
        "# env = Environment.from_conda_specification(name = 'tensorflow-keras-sklearn-training', file_path = './conda_dependencies.yml')\n",
        "# # Specify a GPU base image\n",
        "# env.docker.base_image = 'mcr.microsoft.com/azureml/openmpi3.1.2-cuda10.0-cudnn7-ubuntu18.04'\n",
        "# print(env)\n",
        "\n",
        "# If you used the dockerfile created above...\n",
        "env = Environment.from_dockerfile(name = 'tensorflow-keras-sklearn-training', dockerfile = './dockerfile')\n",
        "print(env)\n",
        "\n",
        "env.register(workspace=ws)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment(Name: tensorflow-keras-sklearn-training,\n",
            "Version: None)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "{\n    \"databricks\": {\n        \"eggLibraries\": [],\n        \"jarLibraries\": [],\n        \"mavenLibraries\": [],\n        \"pypiLibraries\": [],\n        \"rcranLibraries\": []\n    },\n    \"docker\": {\n        \"arguments\": [],\n        \"baseDockerfile\": \"\\nFROM mcr.microsoft.com/azureml/openmpi4.1.0-cuda11.0.3-cudnn8-ubuntu18.04:20210615.v1\\n\\nENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/tensorflow-2.4\\n\\n# Create conda environment\\nRUN conda create -p $AZUREML_CONDA_ENVIRONMENT_PATH \\\\\\n    python=3.7 pip=20.2.4\\n\\n# Prepend path to AzureML conda environment\\nENV PATH $AZUREML_CONDA_ENVIRONMENT_PATH/bin:$PATH\\n\\n# Install pip dependencies\\nRUN HOROVOD_WITH_TENSORFLOW=1 \\\\\\n    pip install 'matplotlib>=3.3,<3.4' \\\\\\n                'psutil>=5.8,<5.9' \\\\\\n                'tqdm>=4.59,<4.60' \\\\\\n                'pandas>=1.1,<1.2' \\\\\\n                'scipy>=1.5,<1.6' \\\\\\n                'numpy>=1.10,<1.20' \\\\\\n                'azureml-core==1.30.0' \\\\\\n                'azureml-defaults==1.30.0' \\\\\\n                'azureml-telemetry==1.30.0' \\\\\\n                'tensorboard==2.4.0' \\\\\\n                'tensorflow-gpu==2.4.1' \\\\\\n                'horovod[tensorflow-gpu]==0.21.3' \\\\\\n                'scikit-learn==0.24.0'\\n\\n# This is needed for mpi to locate libpython\\nENV LD_LIBRARY_PATH $AZUREML_CONDA_ENVIRONMENT_PATH/lib:$LD_LIBRARY_PATH\\n\",\n        \"baseImage\": null,\n        \"baseImageRegistry\": {\n            \"address\": null,\n            \"password\": null,\n            \"registryIdentity\": null,\n            \"username\": null\n        },\n        \"enabled\": false,\n        \"platform\": {\n            \"architecture\": \"amd64\",\n            \"os\": \"Linux\"\n        },\n        \"sharedVolumes\": true,\n        \"shmSize\": null\n    },\n    \"environmentVariables\": {\n        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n    },\n    \"inferencingStackVersion\": null,\n    \"name\": \"tensorflow-keras-sklearn-training\",\n    \"python\": {\n        \"baseCondaEnvironment\": null,\n        \"condaDependencies\": {\n            \"channels\": [\n                \"anaconda\",\n                \"conda-forge\"\n            ],\n            \"dependencies\": [\n                \"python=3.6.2\",\n                {\n                    \"pip\": [\n                        \"azureml-defaults\"\n                    ]\n                }\n            ],\n            \"name\": \"project_environment\"\n        },\n        \"condaDependenciesFile\": null,\n        \"interpreterPath\": \"python\",\n        \"userManagedDependencies\": true\n    },\n    \"r\": null,\n    \"spark\": {\n        \"packages\": [],\n        \"precachePackages\": true,\n        \"repositories\": []\n    },\n    \"version\": \"5\"\n}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1628787240013
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip Kaggle file and only load in the Ethereum data\n",
        "with zipfile.ZipFile('./data/cryptocurrencypricehistory.zip') as myzip:\n",
        "    with myzip.open('coin_Ethereum.csv') as Ethereum:\n",
        "        ETH = pd.read_csv(Ethereum)   \n",
        "    with myzip.open('coin_Bitcoin.csv') as Bitcoin:\n",
        "        BTC = pd.read_csv(Bitcoin)   \n",
        "       \n",
        "ETH.drop(['SNo', 'Name', 'Symbol'], inplace=True, axis=1)\n",
        "BTC.drop(['SNo', 'Name', 'Symbol'], inplace=True, axis=1)\n",
        "\n",
        "crypto = ETH.merge(BTC, how='inner', on='Date', suffixes=['_ETH', '_BTC'])\n",
        "\n",
        "# Change datetime column to be a date and sort by it\n",
        "crypto.loc[:,'Date'] = pd.to_datetime(crypto.Date).dt.date\n",
        "crypto.set_index('Date', inplace=True, drop=True)\n",
        "crypto.sort_index(ascending=True, inplace=True)\n",
        "# Add new columns that prevent data leakage and remove the old ones\n",
        "crypto.loc[:,'LowPrevDay_BTC'] = crypto.Low_BTC.shift(1)\n",
        "crypto.loc[:,'LowPrevDay_ETH'] = crypto.Low_ETH.shift(1)\n",
        "crypto.loc[:,'HighPrevDay_BTC'] = crypto.High_BTC.shift(1)\n",
        "crypto.loc[:,'HighPrevDay_ETH'] = crypto.High_ETH.shift(1)\n",
        "crypto.loc[:,'VolumePrevDay_BTC'] = crypto.Volume_BTC.shift(1)\n",
        "crypto.loc[:,'VolumePrevDay_ETH'] = crypto.Volume_ETH.shift(1)\n",
        "crypto.loc[:,'MarketcapPrevDay_BTC'] = crypto.Marketcap_BTC.shift(1)\n",
        "crypto.loc[:,'MarketcapPrevDay_ETH'] = crypto.Marketcap_ETH.shift(1)\n",
        "crypto.loc[:,'HiLoDiff_ETH'] = crypto.HighPrevDay_ETH - crypto.LowPrevDay_ETH\n",
        "crypto.loc[:,'HiLoDiff_BTC'] = crypto.HighPrevDay_BTC - crypto.LowPrevDay_BTC\n",
        "crypto.loc[:,'Close_MA7_ETH'] = crypto.Close_ETH.rolling(7).mean()\n",
        "crypto.loc[:,'Close_MA14_ETH'] = crypto.Close_ETH.rolling(14).mean()\n",
        "crypto.loc[:,'Close_STDEV7_ETH'] = crypto.Close_ETH.rolling(7).std()\n",
        "crypto.loc[:,'Close_STDEV14_ETH'] = crypto.Close_ETH.rolling(14).std()\n",
        "crypto.drop(['Close_BTC', 'Low_BTC', 'Low_ETH', 'High_BTC', 'High_ETH', 'Volume_BTC', 'Volume_ETH', 'Marketcap_BTC', 'Marketcap_ETH'], axis=1, inplace=True)\n",
        "crypto.drop(index=crypto.index[0], axis=0, inplace=True) \n",
        "crypto.dropna(inplace=True)\n",
        "\n",
        "crypto.to_csv('./data/crypto.csv')\n",
        "crypto = pd.read_csv('./data/crypto.csv')\n",
        "crypto.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "         Date  Open_ETH  Close_ETH    Open_BTC  LowPrevDay_BTC  \\\n0  2015-08-21   1.47752    1.39529  235.354996      226.899002   \n1  2015-08-22   1.39629    1.37923  232.662003      231.723999   \n2  2015-08-23   1.37500    1.35259  230.376007      222.703995   \n3  2015-08-24   1.34559    1.23127  228.112000      225.580002   \n4  2015-08-25   1.22861    1.14019  210.067993      210.442993   \n\n   LowPrevDay_ETH  HighPrevDay_BTC  HighPrevDay_ETH  VolumePrevDay_BTC  \\\n0         1.24833       237.365005          1.53330         32275000.0   \n1         1.35280       236.432007          1.55642         23173800.0   \n2         1.35268       234.957001          1.47641         23205900.0   \n3         1.29777       232.705002          1.40970         18406600.0   \n4         1.23127       228.139008          1.36278         59220700.0   \n\n   VolumePrevDay_ETH  MarketcapPrevDay_BTC  MarketcapPrevDay_ETH  \\\n0          2843760.0          3.417123e+09          1.063514e+08   \n1          2020970.0          3.377704e+09          1.013319e+08   \n2           948310.0          3.346962e+09          1.002018e+08   \n3          1589300.0          3.315467e+09          9.830035e+07   \n4           924920.0          3.059461e+09          8.951526e+07   \n\n   HiLoDiff_ETH  HiLoDiff_BTC  Close_MA7_ETH  Close_MA14_ETH  \\\n0       0.28497     10.466003       1.380666        1.269226   \n1       0.20362      4.708008       1.336427        1.313934   \n2       0.12373     12.253006       1.305936        1.360412   \n3       0.11193      7.125000       1.309887        1.397756   \n4       0.13151     17.696014       1.317479        1.402923   \n\n   Close_STDEV7_ETH  Close_STDEV14_ETH  \n0          0.211769           0.384875  \n1          0.163488           0.355575  \n2          0.130004           0.308881  \n3          0.126755           0.249983  \n4          0.111907           0.243299  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Open_ETH</th>\n      <th>Close_ETH</th>\n      <th>Open_BTC</th>\n      <th>LowPrevDay_BTC</th>\n      <th>LowPrevDay_ETH</th>\n      <th>HighPrevDay_BTC</th>\n      <th>HighPrevDay_ETH</th>\n      <th>VolumePrevDay_BTC</th>\n      <th>VolumePrevDay_ETH</th>\n      <th>MarketcapPrevDay_BTC</th>\n      <th>MarketcapPrevDay_ETH</th>\n      <th>HiLoDiff_ETH</th>\n      <th>HiLoDiff_BTC</th>\n      <th>Close_MA7_ETH</th>\n      <th>Close_MA14_ETH</th>\n      <th>Close_STDEV7_ETH</th>\n      <th>Close_STDEV14_ETH</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2015-08-21</td>\n      <td>1.47752</td>\n      <td>1.39529</td>\n      <td>235.354996</td>\n      <td>226.899002</td>\n      <td>1.24833</td>\n      <td>237.365005</td>\n      <td>1.53330</td>\n      <td>32275000.0</td>\n      <td>2843760.0</td>\n      <td>3.417123e+09</td>\n      <td>1.063514e+08</td>\n      <td>0.28497</td>\n      <td>10.466003</td>\n      <td>1.380666</td>\n      <td>1.269226</td>\n      <td>0.211769</td>\n      <td>0.384875</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2015-08-22</td>\n      <td>1.39629</td>\n      <td>1.37923</td>\n      <td>232.662003</td>\n      <td>231.723999</td>\n      <td>1.35280</td>\n      <td>236.432007</td>\n      <td>1.55642</td>\n      <td>23173800.0</td>\n      <td>2020970.0</td>\n      <td>3.377704e+09</td>\n      <td>1.013319e+08</td>\n      <td>0.20362</td>\n      <td>4.708008</td>\n      <td>1.336427</td>\n      <td>1.313934</td>\n      <td>0.163488</td>\n      <td>0.355575</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2015-08-23</td>\n      <td>1.37500</td>\n      <td>1.35259</td>\n      <td>230.376007</td>\n      <td>222.703995</td>\n      <td>1.35268</td>\n      <td>234.957001</td>\n      <td>1.47641</td>\n      <td>23205900.0</td>\n      <td>948310.0</td>\n      <td>3.346962e+09</td>\n      <td>1.002018e+08</td>\n      <td>0.12373</td>\n      <td>12.253006</td>\n      <td>1.305936</td>\n      <td>1.360412</td>\n      <td>0.130004</td>\n      <td>0.308881</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2015-08-24</td>\n      <td>1.34559</td>\n      <td>1.23127</td>\n      <td>228.112000</td>\n      <td>225.580002</td>\n      <td>1.29777</td>\n      <td>232.705002</td>\n      <td>1.40970</td>\n      <td>18406600.0</td>\n      <td>1589300.0</td>\n      <td>3.315467e+09</td>\n      <td>9.830035e+07</td>\n      <td>0.11193</td>\n      <td>7.125000</td>\n      <td>1.309887</td>\n      <td>1.397756</td>\n      <td>0.126755</td>\n      <td>0.249983</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2015-08-25</td>\n      <td>1.22861</td>\n      <td>1.14019</td>\n      <td>210.067993</td>\n      <td>210.442993</td>\n      <td>1.23127</td>\n      <td>228.139008</td>\n      <td>1.36278</td>\n      <td>59220700.0</td>\n      <td>924920.0</td>\n      <td>3.059461e+09</td>\n      <td>8.951526e+07</td>\n      <td>0.13151</td>\n      <td>17.696014</td>\n      <td>1.317479</td>\n      <td>1.402923</td>\n      <td>0.111907</td>\n      <td>0.243299</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1628787241897
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the data to the datastore\n",
        "datastore.upload_files(files = ['./data/crypto.csv'],\n",
        "                       target_path = 'crypto/',\n",
        "                       overwrite = True,\n",
        "                       show_progress = True)\n",
        "# See if the data is there \n",
        "dataset = Dataset.Tabular.from_delimited_files(path = [(datastore, 'crypto/crypto.csv')])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading an estimated of 1 files\n",
            "Uploading ./data/crypto.csv\n",
            "Uploaded ./data/crypto.csv, 1 files out of an estimated total of 1\n",
            "Uploaded 1 files\n"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1628787248913
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Try to get the registered dataset. If its not there, register it\n",
        "dataset_registered = False\n",
        "try:\n",
        "    temp = Dataset.get_by_name(workspace = ws, name = 'crypto')\n",
        "    dataset_registered = True\n",
        "except:\n",
        "    print(\"The dataset 'crypto' is not registered in workspace yet.\")\n",
        "\n",
        "if not dataset_registered:\n",
        "    dataset = dataset.register(\n",
        "        workspace = ws,\n",
        "        name = 'crypto',\n",
        "        description='training and test dataset',\n",
        "        create_new_version=True\n",
        "        )\n",
        "\n",
        "# Check to make sure the data is the way you expect it after moving it around from Kaggle to your environment to the datastore to a registered dataset\n",
        "crypto = dataset.to_pandas_dataframe()\n",
        "crypto.set_index('Date', inplace=True, drop=True)\n",
        "crypto.sort_index(ascending=True, inplace=True)\n",
        "crypto.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "            Open_ETH  Close_ETH    Open_BTC  LowPrevDay_BTC  LowPrevDay_ETH  \\\nDate                                                                          \n2015-08-21   1.47752    1.39529  235.354996      226.899002         1.24833   \n2015-08-22   1.39629    1.37923  232.662003      231.723999         1.35280   \n2015-08-23   1.37500    1.35259  230.376007      222.703995         1.35268   \n2015-08-24   1.34559    1.23127  228.112000      225.580002         1.29777   \n2015-08-25   1.22861    1.14019  210.067993      210.442993         1.23127   \n\n            HighPrevDay_BTC  HighPrevDay_ETH  VolumePrevDay_BTC  \\\nDate                                                              \n2015-08-21       237.365005          1.53330         32275000.0   \n2015-08-22       236.432007          1.55642         23173800.0   \n2015-08-23       234.957001          1.47641         23205900.0   \n2015-08-24       232.705002          1.40970         18406600.0   \n2015-08-25       228.139008          1.36278         59220700.0   \n\n            VolumePrevDay_ETH  MarketcapPrevDay_BTC  MarketcapPrevDay_ETH  \\\nDate                                                                        \n2015-08-21          2843760.0          3.417123e+09          1.063514e+08   \n2015-08-22          2020970.0          3.377704e+09          1.013319e+08   \n2015-08-23           948310.0          3.346962e+09          1.002018e+08   \n2015-08-24          1589300.0          3.315467e+09          9.830035e+07   \n2015-08-25           924920.0          3.059461e+09          8.951526e+07   \n\n            HiLoDiff_ETH  HiLoDiff_BTC  Close_MA7_ETH  Close_MA14_ETH  \\\nDate                                                                    \n2015-08-21       0.28497     10.466003       1.380666        1.269226   \n2015-08-22       0.20362      4.708008       1.336427        1.313934   \n2015-08-23       0.12373     12.253006       1.305936        1.360412   \n2015-08-24       0.11193      7.125000       1.309887        1.397756   \n2015-08-25       0.13151     17.696014       1.317479        1.402923   \n\n            Close_STDEV7_ETH  Close_STDEV14_ETH  \nDate                                             \n2015-08-21          0.211769           0.384875  \n2015-08-22          0.163488           0.355575  \n2015-08-23          0.130004           0.308881  \n2015-08-24          0.126755           0.249983  \n2015-08-25          0.111907           0.243299  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Open_ETH</th>\n      <th>Close_ETH</th>\n      <th>Open_BTC</th>\n      <th>LowPrevDay_BTC</th>\n      <th>LowPrevDay_ETH</th>\n      <th>HighPrevDay_BTC</th>\n      <th>HighPrevDay_ETH</th>\n      <th>VolumePrevDay_BTC</th>\n      <th>VolumePrevDay_ETH</th>\n      <th>MarketcapPrevDay_BTC</th>\n      <th>MarketcapPrevDay_ETH</th>\n      <th>HiLoDiff_ETH</th>\n      <th>HiLoDiff_BTC</th>\n      <th>Close_MA7_ETH</th>\n      <th>Close_MA14_ETH</th>\n      <th>Close_STDEV7_ETH</th>\n      <th>Close_STDEV14_ETH</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2015-08-21</th>\n      <td>1.47752</td>\n      <td>1.39529</td>\n      <td>235.354996</td>\n      <td>226.899002</td>\n      <td>1.24833</td>\n      <td>237.365005</td>\n      <td>1.53330</td>\n      <td>32275000.0</td>\n      <td>2843760.0</td>\n      <td>3.417123e+09</td>\n      <td>1.063514e+08</td>\n      <td>0.28497</td>\n      <td>10.466003</td>\n      <td>1.380666</td>\n      <td>1.269226</td>\n      <td>0.211769</td>\n      <td>0.384875</td>\n    </tr>\n    <tr>\n      <th>2015-08-22</th>\n      <td>1.39629</td>\n      <td>1.37923</td>\n      <td>232.662003</td>\n      <td>231.723999</td>\n      <td>1.35280</td>\n      <td>236.432007</td>\n      <td>1.55642</td>\n      <td>23173800.0</td>\n      <td>2020970.0</td>\n      <td>3.377704e+09</td>\n      <td>1.013319e+08</td>\n      <td>0.20362</td>\n      <td>4.708008</td>\n      <td>1.336427</td>\n      <td>1.313934</td>\n      <td>0.163488</td>\n      <td>0.355575</td>\n    </tr>\n    <tr>\n      <th>2015-08-23</th>\n      <td>1.37500</td>\n      <td>1.35259</td>\n      <td>230.376007</td>\n      <td>222.703995</td>\n      <td>1.35268</td>\n      <td>234.957001</td>\n      <td>1.47641</td>\n      <td>23205900.0</td>\n      <td>948310.0</td>\n      <td>3.346962e+09</td>\n      <td>1.002018e+08</td>\n      <td>0.12373</td>\n      <td>12.253006</td>\n      <td>1.305936</td>\n      <td>1.360412</td>\n      <td>0.130004</td>\n      <td>0.308881</td>\n    </tr>\n    <tr>\n      <th>2015-08-24</th>\n      <td>1.34559</td>\n      <td>1.23127</td>\n      <td>228.112000</td>\n      <td>225.580002</td>\n      <td>1.29777</td>\n      <td>232.705002</td>\n      <td>1.40970</td>\n      <td>18406600.0</td>\n      <td>1589300.0</td>\n      <td>3.315467e+09</td>\n      <td>9.830035e+07</td>\n      <td>0.11193</td>\n      <td>7.125000</td>\n      <td>1.309887</td>\n      <td>1.397756</td>\n      <td>0.126755</td>\n      <td>0.249983</td>\n    </tr>\n    <tr>\n      <th>2015-08-25</th>\n      <td>1.22861</td>\n      <td>1.14019</td>\n      <td>210.067993</td>\n      <td>210.442993</td>\n      <td>1.23127</td>\n      <td>228.139008</td>\n      <td>1.36278</td>\n      <td>59220700.0</td>\n      <td>924920.0</td>\n      <td>3.059461e+09</td>\n      <td>8.951526e+07</td>\n      <td>0.13151</td>\n      <td>17.696014</td>\n      <td>1.317479</td>\n      <td>1.402923</td>\n      <td>0.111907</td>\n      <td>0.243299</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1628787249887
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import argparse\r\n",
        "# import json\r\n",
        "# import os\r\n",
        "# import zipfile\r\n",
        "# import pandas as pd\r\n",
        "# import numpy as np\r\n",
        "# import matplotlib.pyplot as plt\r\n",
        "# from sklearn.preprocessing import MinMaxScaler\r\n",
        "# from tensorflow.keras.models import Sequential\r\n",
        "# from tensorflow.keras.layers import Dense, Dropout, LSTM\r\n",
        "# from tensorflow.keras.metrics import RootMeanSquaredError\r\n",
        "# from tensorflow.keras.callbacks import Callback\r\n",
        "# from azureml.core import Run\r\n",
        "# from azureml.core import Dataset\r\n",
        "# from azureml.core.workspace import Workspace\r\n",
        "\r\n",
        "# def dnn_prep(df):\r\n",
        "#     target_col = ['Close_ETH']\r\n",
        "#     df = df[[c for c in df if c not in target_col] + target_col]\r\n",
        "#     values = df.values.astype('float32')\r\n",
        "#     scaler = MinMaxScaler(feature_range=(0, 1))\r\n",
        "#     scaled = scaler.fit_transform(values)\r\n",
        "#     X, y = scaled[:100, :-1], scaled[:100, -1] ########## REMOVE 100s AFTER TESTING ############\r\n",
        "#     X = X.reshape(X.shape[0], 1, X.shape[1])\r\n",
        "#     return X, y, scaler\r\n",
        "\r\n",
        "\r\n",
        "# # -------------------------------------------------------------------\r\n",
        "\r\n",
        "# print(crypto.head())\r\n",
        "\r\n",
        "# train_size = int(round(crypto.shape[0]*0.8, 0))\r\n",
        "# val_size = int(round(crypto.shape[0]*0.1, 0))\r\n",
        "# train_df = crypto.iloc[0:train_size,:]\r\n",
        "# val_df = crypto.iloc[train_size:(train_size + val_size),:]\r\n",
        "# test_df = crypto.iloc[(train_size + val_size):crypto.shape[0],:]\r\n",
        "# print(train_df.shape, val_df.shape, test_df.shape)\r\n",
        "# X_train, y_train, scaler_train = dnn_prep(train_df)\r\n",
        "# X_val, y_val, scaler_val = dnn_prep(val_df)\r\n",
        "\r\n",
        "\r\n",
        "# # Build an LSTM model\r\n",
        "# model = Sequential()\r\n",
        "# model.add(LSTM(32, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\r\n",
        "# model.add(Dropout(0.1))\r\n",
        "# model.add(LSTM(16, return_sequences=False))\r\n",
        "# model.add(Dropout(0.1))\r\n",
        "# model.add(Dense(1))\r\n",
        "\r\n",
        "# # Compile the model\r\n",
        "# model.compile(optimizer='adam', loss='mse', metrics=[RootMeanSquaredError(), 'mae', 'mape'])\r\n",
        "\r\n",
        "# epochs=10\r\n",
        "\r\n",
        "# history = model.fit(\r\n",
        "#     X_train, y_train,\r\n",
        "#     epochs=epochs,\r\n",
        "#     verbose=0,\r\n",
        "#     validation_data=(X_val, y_val)\r\n",
        "# )\r\n",
        "\r\n",
        "# print(history)\r\n",
        "\r\n",
        "# score = model.evaluate(X_val, y_val, verbose=0)\r\n",
        "# rmse = score[0]\r\n",
        "# print('Root Mean Squared Error:', rmse)\r\n",
        "# mae = score[1]\r\n",
        "# print('Mean Absolute Error:', mae)\r\n",
        "# mape = score[2]\r\n",
        "# print('Mean Absolute Percentage Error:', mape)\r\n",
        "\r\n",
        "# plt.figure(figsize=(6, 3))\r\n",
        "# plt.title('ETH prediction ({} epochs)'.format(epochs), fontsize=14)\r\n",
        "# plt.plot(history.history['root_mean_squared_error'], 'b--', label='Train RMSE', lw=4, alpha=0.5)\r\n",
        "# plt.plot(history.history['val_root_mean_squared_error'], 'r--', label='Val RMSE', lw=4, alpha=0.5)\r\n",
        "# plt.legend(fontsize=12)\r\n",
        "# plt.grid(True)\r\n",
        "# plt.show()\r\n",
        "\r\n",
        "# history.history"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628787250032
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperdrive Configuration\n",
        "\n",
        "TODO: Explain the model you are using and the reason for chosing the different hyperparameters, termination policy and config settings.\n",
        "\n",
        "Its important to make note of the version of keras we are training with so we can use the same version to load it during inference. This can be found in the outputs of the training runs"
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598531923519
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the different params that you will be using during training\n",
        "# \"Note that only choice, quniform, and uniform are supported for Bayesian optimization\" https://docs.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.hyperdrive.bayesianparametersampling?view=azure-ml-py#parameters\n",
        "param_sampling = BayesianParameterSampling(\n",
        "    {\n",
        "        'hidden': choice(32, 64, 128),\n",
        "        'learning_rate': uniform(0.001, 0.1),\n",
        "        'dropout': uniform(0, 0.25)\n",
        "    }\n",
        ")\n",
        "\n",
        "# Create an estimator by running crypto_train.py\n",
        "args = ['--input_data', dataset.as_named_input('crypto')]\n",
        "docker_config = DockerConfiguration(use_docker=True)\n",
        "src = ScriptRunConfig(\n",
        "    source_directory='.', \n",
        "    script='crypto_train.py', \n",
        "    arguments=args,\n",
        "    compute_target=compute_target,\n",
        "    environment=env,\n",
        "    docker_runtime_config=docker_config\n",
        ")\n",
        "\n",
        "\n",
        "# Create a HyperDriveConfig using the estimator, hyperparameter sampler, and policy.\n",
        "hyperdrive_run_config = HyperDriveConfig(\n",
        "    run_config=src, \n",
        "    hyperparameter_sampling=param_sampling, \n",
        "    primary_metric_name='Root Mean Squared Error', \n",
        "    primary_metric_goal=PrimaryMetricGoal.MINIMIZE, \n",
        "    max_total_runs=3\n",
        ") "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "For best results with Bayesian Sampling we recommend using a maximum number of runs greater than or equal to 20 times the number of hyperparameters being tuned. Recommendend value:60.\n"
          ]
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1628787250115
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit your hyperdrive run to the experiment and show run details with the widget.\n",
        "hyperdrive_run = experiment.submit(hyperdrive_run_config)\n",
        "print(\"Run submitted for execution.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run submitted for execution.\n"
          ]
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1628787267437
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Details\n",
        "\n",
        "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\n",
        "\n",
        "TODO: In the cell below, use the `RunDetails` widget to show the different experiments."
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598544898497
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RunDetails(hyperdrive_run).show()\n",
        "hyperdrive_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_HyperDriveWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO'…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f8d483606eed450d9e724d7fe0187721"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/HD_b8ab1926-a58a-4f61-ac15-0b7a0c9d3aa6?wsid=/subscriptions/ac401033-05b1-43d5-a5ea-e5dcb9c75b49/resourcegroups/rg-devtest-databricks-01/workspaces/ml-devtest&tid=fa1a69b7-9b39-4cb7-8701-41985a92e9bb\", \"run_id\": \"HD_b8ab1926-a58a-4f61-ac15-0b7a0c9d3aa6\", \"run_properties\": {\"run_id\": \"HD_b8ab1926-a58a-4f61-ac15-0b7a0c9d3aa6\", \"created_utc\": \"2021-08-12T16:54:25.927308Z\", \"properties\": {\"primary_metric_config\": \"{\\\"name\\\": \\\"Root Mean Squared Error\\\", \\\"goal\\\": \\\"minimize\\\"}\", \"resume_from\": \"null\", \"runTemplate\": \"HyperDrive\", \"azureml.runsource\": \"hyperdrive\", \"platform\": \"AML\", \"ContentSnapshotId\": \"9d56e277-31a7-4c4a-bb7a-408d302bae05\", \"user_agent\": \"python/3.6.9 (Linux-5.4.0-1051-azure-x86_64-with-debian-buster-sid) msrest/0.6.21 Hyperdrive.Service/1.0.0 Hyperdrive.SDK/core.1.31.0\", \"score\": \"0.00032465814729221165\", \"best_child_run_id\": \"HD_b8ab1926-a58a-4f61-ac15-0b7a0c9d3aa6_0\", \"best_metric_status\": \"Succeeded\"}, \"tags\": {\"_aml_system_max_concurrent_jobs\": \"3\", \"max_concurrent_jobs\": \"3\", \"_aml_system_max_total_jobs\": \"3\", \"max_total_jobs\": \"3\", \"_aml_system_max_duration_minutes\": \"10080\", \"max_duration_minutes\": \"10080\", \"_aml_system_policy_config\": \"{\\\"name\\\": \\\"DEFAULT\\\"}\", \"policy_config\": \"{\\\"name\\\": \\\"DEFAULT\\\"}\", \"_aml_system_generator_config\": \"{\\\"name\\\": \\\"BAYESIANOPTIMIZATION\\\", \\\"parameter_space\\\": {\\\"hidden\\\": [\\\"choice\\\", [[32, 64, 128]]], \\\"learning_rate\\\": [\\\"uniform\\\", [0.001, 0.1]], \\\"dropout\\\": [\\\"uniform\\\", [0, 0.25]]}}\", \"generator_config\": \"{\\\"name\\\": \\\"BAYESIANOPTIMIZATION\\\", \\\"parameter_space\\\": {\\\"hidden\\\": [\\\"choice\\\", [[32, 64, 128]]], \\\"learning_rate\\\": [\\\"uniform\\\", [0.001, 0.1]], \\\"dropout\\\": [\\\"uniform\\\", [0, 0.25]]}}\", \"_aml_system_primary_metric_config\": \"{\\\"name\\\": \\\"Root Mean Squared Error\\\", \\\"goal\\\": \\\"minimize\\\"}\", \"primary_metric_config\": \"{\\\"name\\\": \\\"Root Mean Squared Error\\\", \\\"goal\\\": \\\"minimize\\\"}\", \"_aml_system_platform_config\": \"{\\\"ServiceAddress\\\": \\\"https://centralus.experiments.azureml.net\\\", \\\"ServiceArmScope\\\": \\\"subscriptions/ac401033-05b1-43d5-a5ea-e5dcb9c75b49/resourceGroups/rg-devtest-databricks-01/providers/Microsoft.MachineLearningServices/workspaces/ml-devtest/experiments/capstone-project\\\", \\\"SubscriptionId\\\": \\\"ac401033-05b1-43d5-a5ea-e5dcb9c75b49\\\", \\\"ResourceGroupName\\\": \\\"rg-devtest-databricks-01\\\", \\\"WorkspaceName\\\": \\\"ml-devtest\\\", \\\"ExperimentName\\\": \\\"capstone-project\\\", \\\"Definition\\\": {\\\"Overrides\\\": {\\\"script\\\": \\\"crypto_train.py\\\", \\\"arguments\\\": [\\\"--input_data\\\", \\\"DatasetConsumptionConfig:crypto\\\"], \\\"target\\\": \\\"capstone-compute\\\", \\\"framework\\\": \\\"Python\\\", \\\"communicator\\\": \\\"None\\\", \\\"maxRunDurationSeconds\\\": 2592000, \\\"nodeCount\\\": 1, \\\"priority\\\": null, \\\"environment\\\": {\\\"name\\\": \\\"tensorflow-keras-sklearn-training\\\", \\\"version\\\": null, \\\"environmentVariables\\\": {\\\"EXAMPLE_ENV_VAR\\\": \\\"EXAMPLE_VALUE\\\"}, \\\"python\\\": {\\\"userManagedDependencies\\\": true, \\\"interpreterPath\\\": \\\"python\\\", \\\"condaDependenciesFile\\\": null, \\\"baseCondaEnvironment\\\": null, \\\"condaDependencies\\\": {\\\"name\\\": \\\"project_environment\\\", \\\"dependencies\\\": [\\\"python=3.6.2\\\", {\\\"pip\\\": [\\\"azureml-defaults\\\"]}], \\\"channels\\\": [\\\"anaconda\\\", \\\"conda-forge\\\"]}}, \\\"docker\\\": {\\\"enabled\\\": false, \\\"baseImage\\\": null, \\\"baseDockerfile\\\": \\\"\\\\nFROM mcr.microsoft.com/azureml/openmpi4.1.0-cuda11.0.3-cudnn8-ubuntu18.04:20210615.v1\\\\n\\\\nENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/tensorflow-2.4\\\\n\\\\n# Create conda environment\\\\nRUN conda create -p $AZUREML_CONDA_ENVIRONMENT_PATH \\\\\\\\\\\\n    python=3.7 pip=20.2.4\\\\n\\\\n# Prepend path to AzureML conda environment\\\\nENV PATH $AZUREML_CONDA_ENVIRONMENT_PATH/bin:$PATH\\\\n\\\\n# Install pip dependencies\\\\nRUN HOROVOD_WITH_TENSORFLOW=1 \\\\\\\\\\\\n    pip install 'matplotlib>=3.3,<3.4' \\\\\\\\\\\\n                'psutil>=5.8,<5.9' \\\\\\\\\\\\n                'tqdm>=4.59,<4.60' \\\\\\\\\\\\n                'pandas>=1.1,<1.2' \\\\\\\\\\\\n                'scipy>=1.5,<1.6' \\\\\\\\\\\\n                'numpy>=1.10,<1.20' \\\\\\\\\\\\n                'azureml-core==1.30.0' \\\\\\\\\\\\n                'azureml-defaults==1.30.0' \\\\\\\\\\\\n                'azureml-telemetry==1.30.0' \\\\\\\\\\\\n                'tensorboard==2.4.0' \\\\\\\\\\\\n                'tensorflow-gpu==2.4.1' \\\\\\\\\\\\n                'horovod[tensorflow-gpu]==0.21.3' \\\\\\\\\\\\n                'scikit-learn==0.24.0'\\\\n\\\\n# This is needed for mpi to locate libpython\\\\nENV LD_LIBRARY_PATH $AZUREML_CONDA_ENVIRONMENT_PATH/lib:$LD_LIBRARY_PATH\\\\n\\\", \\\"sharedVolumes\\\": true, \\\"shmSize\\\": \\\"2g\\\", \\\"arguments\\\": [], \\\"baseImageRegistry\\\": {\\\"address\\\": null, \\\"username\\\": null, \\\"password\\\": null, \\\"registryIdentity\\\": null}, \\\"platform\\\": {\\\"os\\\": \\\"Linux\\\", \\\"architecture\\\": \\\"amd64\\\"}}, \\\"spark\\\": {\\\"repositories\\\": [], \\\"packages\\\": [], \\\"precachePackages\\\": true}, \\\"databricks\\\": {\\\"mavenLibraries\\\": [], \\\"pypiLibraries\\\": [], \\\"rcranLibraries\\\": [], \\\"jarLibraries\\\": [], \\\"eggLibraries\\\": []}, \\\"r\\\": null, \\\"inferencingStackVersion\\\": null}, \\\"history\\\": {\\\"outputCollection\\\": true, \\\"snapshotProject\\\": true, \\\"directoriesToWatch\\\": [\\\"logs\\\"]}, \\\"spark\\\": {\\\"configuration\\\": {\\\"spark.app.name\\\": \\\"Azure ML Experiment\\\", \\\"spark.yarn.maxAppAttempts\\\": 1}}, \\\"docker\\\": {\\\"useDocker\\\": true, \\\"sharedVolumes\\\": true, \\\"arguments\\\": [], \\\"shmSize\\\": \\\"2g\\\"}, \\\"hdi\\\": {\\\"yarnDeployMode\\\": \\\"cluster\\\"}, \\\"tensorflow\\\": {\\\"workerCount\\\": 1, \\\"parameterServerCount\\\": 1}, \\\"mpi\\\": {\\\"processCountPerNode\\\": 1, \\\"nodeCount\\\": 1}, \\\"pytorch\\\": {\\\"communicationBackend\\\": \\\"nccl\\\", \\\"processCount\\\": null, \\\"nodeCount\\\": 1}, \\\"paralleltask\\\": {\\\"maxRetriesPerWorker\\\": 0, \\\"workerCountPerNode\\\": 1, \\\"terminalExitCodes\\\": null}, \\\"dataReferences\\\": {}, \\\"data\\\": {\\\"crypto\\\": {\\\"dataLocation\\\": {\\\"dataset\\\": {\\\"id\\\": \\\"0cb8b2aa-aedf-45f6-b7d6-fc86b399984a\\\", \\\"name\\\": null, \\\"version\\\": null}, \\\"dataPath\\\": null, \\\"uri\\\": null}, \\\"createOutputDirectories\\\": false, \\\"mechanism\\\": \\\"direct\\\", \\\"environmentVariableName\\\": \\\"crypto\\\", \\\"pathOnCompute\\\": null, \\\"overwrite\\\": false}}, \\\"outputData\\\": {}, \\\"sourceDirectoryDataStore\\\": null, \\\"amlcompute\\\": {\\\"vmSize\\\": null, \\\"vmPriority\\\": null, \\\"retainCluster\\\": false, \\\"name\\\": null, \\\"clusterMaxNodeCount\\\": null}, \\\"credentialPassthrough\\\": false, \\\"command\\\": \\\"\\\"}, \\\"TargetDetails\\\": null, \\\"SnapshotId\\\": \\\"9d56e277-31a7-4c4a-bb7a-408d302bae05\\\", \\\"TelemetryValues\\\": {\\\"amlClientType\\\": \\\"azureml-sdk-train\\\", \\\"amlClientModule\\\": \\\"[Scrubbed]\\\", \\\"amlClientFunction\\\": \\\"[Scrubbed]\\\", \\\"tenantId\\\": \\\"fa1a69b7-9b39-4cb7-8701-41985a92e9bb\\\", \\\"amlClientRequestId\\\": \\\"cf13f1d1-85a1-4c7a-bf16-8bd22dfb0b51\\\", \\\"amlClientSessionId\\\": \\\"7f8ce4e2-7af1-45e5-9bbb-15fa334d492a\\\", \\\"subscriptionId\\\": \\\"ac401033-05b1-43d5-a5ea-e5dcb9c75b49\\\", \\\"estimator\\\": \\\"NoneType\\\", \\\"samplingMethod\\\": \\\"BayesianOptimization\\\", \\\"terminationPolicy\\\": \\\"Default\\\", \\\"primaryMetricGoal\\\": \\\"minimize\\\", \\\"maxTotalRuns\\\": 3, \\\"maxConcurrentRuns\\\": 3, \\\"maxDurationMinutes\\\": 10080, \\\"vmSize\\\": null}}}\", \"platform_config\": \"{\\\"ServiceAddress\\\": \\\"https://centralus.experiments.azureml.net\\\", \\\"ServiceArmScope\\\": \\\"subscriptions/ac401033-05b1-43d5-a5ea-e5dcb9c75b49/resourceGroups/rg-devtest-databricks-01/providers/Microsoft.MachineLearningServices/workspaces/ml-devtest/experiments/capstone-project\\\", \\\"SubscriptionId\\\": \\\"ac401033-05b1-43d5-a5ea-e5dcb9c75b49\\\", \\\"ResourceGroupName\\\": \\\"rg-devtest-databricks-01\\\", \\\"WorkspaceName\\\": \\\"ml-devtest\\\", \\\"ExperimentName\\\": \\\"capstone-project\\\", \\\"Definition\\\": {\\\"Overrides\\\": {\\\"script\\\": \\\"crypto_train.py\\\", \\\"arguments\\\": [\\\"--input_data\\\", \\\"DatasetConsumptionConfig:crypto\\\"], \\\"target\\\": \\\"capstone-compute\\\", \\\"framework\\\": \\\"Python\\\", \\\"communicator\\\": \\\"None\\\", \\\"maxRunDurationSeconds\\\": 2592000, \\\"nodeCount\\\": 1, \\\"priority\\\": null, \\\"environment\\\": {\\\"name\\\": \\\"tensorflow-keras-sklearn-training\\\", \\\"version\\\": null, \\\"environmentVariables\\\": {\\\"EXAMPLE_ENV_VAR\\\": \\\"EXAMPLE_VALUE\\\"}, \\\"python\\\": {\\\"userManagedDependencies\\\": true, \\\"interpreterPath\\\": \\\"python\\\", \\\"condaDependenciesFile\\\": null, \\\"baseCondaEnvironment\\\": null, \\\"condaDependencies\\\": {\\\"name\\\": \\\"project_environment\\\", \\\"dependencies\\\": [\\\"python=3.6.2\\\", {\\\"pip\\\": [\\\"azureml-defaults\\\"]}], \\\"channels\\\": [\\\"anaconda\\\", \\\"conda-forge\\\"]}}, \\\"docker\\\": {\\\"enabled\\\": false, \\\"baseImage\\\": null, \\\"baseDockerfile\\\": \\\"\\\\nFROM mcr.microsoft.com/azureml/openmpi4.1.0-cuda11.0.3-cudnn8-ubuntu18.04:20210615.v1\\\\n\\\\nENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/tensorflow-2.4\\\\n\\\\n# Create conda environment\\\\nRUN conda create -p $AZUREML_CONDA_ENVIRONMENT_PATH \\\\\\\\\\\\n    python=3.7 pip=20.2.4\\\\n\\\\n# Prepend path to AzureML conda environment\\\\nENV PATH $AZUREML_CONDA_ENVIRONMENT_PATH/bin:$PATH\\\\n\\\\n# Install pip dependencies\\\\nRUN HOROVOD_WITH_TENSORFLOW=1 \\\\\\\\\\\\n    pip install 'matplotlib>=3.3,<3.4' \\\\\\\\\\\\n                'psutil>=5.8,<5.9' \\\\\\\\\\\\n                'tqdm>=4.59,<4.60' \\\\\\\\\\\\n                'pandas>=1.1,<1.2' \\\\\\\\\\\\n                'scipy>=1.5,<1.6' \\\\\\\\\\\\n                'numpy>=1.10,<1.20' \\\\\\\\\\\\n                'azureml-core==1.30.0' \\\\\\\\\\\\n                'azureml-defaults==1.30.0' \\\\\\\\\\\\n                'azureml-telemetry==1.30.0' \\\\\\\\\\\\n                'tensorboard==2.4.0' \\\\\\\\\\\\n                'tensorflow-gpu==2.4.1' \\\\\\\\\\\\n                'horovod[tensorflow-gpu]==0.21.3' \\\\\\\\\\\\n                'scikit-learn==0.24.0'\\\\n\\\\n# This is needed for mpi to locate libpython\\\\nENV LD_LIBRARY_PATH $AZUREML_CONDA_ENVIRONMENT_PATH/lib:$LD_LIBRARY_PATH\\\\n\\\", \\\"sharedVolumes\\\": true, \\\"shmSize\\\": \\\"2g\\\", \\\"arguments\\\": [], \\\"baseImageRegistry\\\": {\\\"address\\\": null, \\\"username\\\": null, \\\"password\\\": null, \\\"registryIdentity\\\": null}, \\\"platform\\\": {\\\"os\\\": \\\"Linux\\\", \\\"architecture\\\": \\\"amd64\\\"}}, \\\"spark\\\": {\\\"repositories\\\": [], \\\"packages\\\": [], \\\"precachePackages\\\": true}, \\\"databricks\\\": {\\\"mavenLibraries\\\": [], \\\"pypiLibraries\\\": [], \\\"rcranLibraries\\\": [], \\\"jarLibraries\\\": [], \\\"eggLibraries\\\": []}, \\\"r\\\": null, \\\"inferencingStackVersion\\\": null}, \\\"history\\\": {\\\"outputCollection\\\": true, \\\"snapshotProject\\\": true, \\\"directoriesToWatch\\\": [\\\"logs\\\"]}, \\\"spark\\\": {\\\"configuration\\\": {\\\"spark.app.name\\\": \\\"Azure ML Experiment\\\", \\\"spark.yarn.maxAppAttempts\\\": 1}}, \\\"docker\\\": {\\\"useDocker\\\": true, \\\"sharedVolumes\\\": true, \\\"arguments\\\": [], \\\"shmSize\\\": \\\"2g\\\"}, \\\"hdi\\\": {\\\"yarnDeployMode\\\": \\\"cluster\\\"}, \\\"tensorflow\\\": {\\\"workerCount\\\": 1, \\\"parameterServerCount\\\": 1}, \\\"mpi\\\": {\\\"processCountPerNode\\\": 1, \\\"nodeCount\\\": 1}, \\\"pytorch\\\": {\\\"communicationBackend\\\": \\\"nccl\\\", \\\"processCount\\\": null, \\\"nodeCount\\\": 1}, \\\"paralleltask\\\": {\\\"maxRetriesPerWorker\\\": 0, \\\"workerCountPerNode\\\": 1, \\\"terminalExitCodes\\\": null}, \\\"dataReferences\\\": {}, \\\"data\\\": {\\\"crypto\\\": {\\\"dataLocation\\\": {\\\"dataset\\\": {\\\"id\\\": \\\"0cb8b2aa-aedf-45f6-b7d6-fc86b399984a\\\", \\\"name\\\": null, \\\"version\\\": null}, \\\"dataPath\\\": null, \\\"uri\\\": null}, \\\"createOutputDirectories\\\": false, \\\"mechanism\\\": \\\"direct\\\", \\\"environmentVariableName\\\": \\\"crypto\\\", \\\"pathOnCompute\\\": null, \\\"overwrite\\\": false}}, \\\"outputData\\\": {}, \\\"sourceDirectoryDataStore\\\": null, \\\"amlcompute\\\": {\\\"vmSize\\\": null, \\\"vmPriority\\\": null, \\\"retainCluster\\\": false, \\\"name\\\": null, \\\"clusterMaxNodeCount\\\": null}, \\\"credentialPassthrough\\\": false, \\\"command\\\": \\\"\\\"}, \\\"TargetDetails\\\": null, \\\"SnapshotId\\\": \\\"9d56e277-31a7-4c4a-bb7a-408d302bae05\\\", \\\"TelemetryValues\\\": {\\\"amlClientType\\\": \\\"azureml-sdk-train\\\", \\\"amlClientModule\\\": \\\"[Scrubbed]\\\", \\\"amlClientFunction\\\": \\\"[Scrubbed]\\\", \\\"tenantId\\\": \\\"fa1a69b7-9b39-4cb7-8701-41985a92e9bb\\\", \\\"amlClientRequestId\\\": \\\"cf13f1d1-85a1-4c7a-bf16-8bd22dfb0b51\\\", \\\"amlClientSessionId\\\": \\\"7f8ce4e2-7af1-45e5-9bbb-15fa334d492a\\\", \\\"subscriptionId\\\": \\\"ac401033-05b1-43d5-a5ea-e5dcb9c75b49\\\", \\\"estimator\\\": \\\"NoneType\\\", \\\"samplingMethod\\\": \\\"BayesianOptimization\\\", \\\"terminationPolicy\\\": \\\"Default\\\", \\\"primaryMetricGoal\\\": \\\"minimize\\\", \\\"maxTotalRuns\\\": 3, \\\"maxConcurrentRuns\\\": 3, \\\"maxDurationMinutes\\\": 10080, \\\"vmSize\\\": null}}}\", \"_aml_system_resume_child_runs\": \"null\", \"resume_child_runs\": \"null\", \"_aml_system_all_jobs_generated\": \"true\", \"all_jobs_generated\": \"true\", \"_aml_system_cancellation_requested\": \"false\", \"cancellation_requested\": \"false\", \"_aml_system_progress_metadata_evaluation_timestamp\": \"\\\"2021-08-12T16:54:26.824383\\\"\", \"progress_metadata_evaluation_timestamp\": \"\\\"2021-08-12T16:54:26.824383\\\"\", \"_aml_system_progress_metadata_digest\": \"\\\"40fa4bbb9daf94397d023f6cf84c05ee2b18e88d05cf79a63a5ecd4355560033\\\"\", \"progress_metadata_digest\": \"\\\"40fa4bbb9daf94397d023f6cf84c05ee2b18e88d05cf79a63a5ecd4355560033\\\"\", \"_aml_system_progress_metadata_active_timestamp\": \"\\\"2021-08-12T16:54:26.824383\\\"\", \"progress_metadata_active_timestamp\": \"\\\"2021-08-12T16:54:26.824383\\\"\", \"_aml_system_optimizer_state_artifact\": \"null\", \"_aml_system_outdated_optimizer_state_artifacts\": \"\\\"[]\\\"\", \"_aml_system_HD_b8ab1926-a58a-4f61-ac15-0b7a0c9d3aa6_0\": \"{\\\"hidden\\\": 64, \\\"learning_rate\\\": 0.07660676721573413, \\\"dropout\\\": 0.2278440588743216}\", \"HD_b8ab1926-a58a-4f61-ac15-0b7a0c9d3aa6_0\": \"{\\\"hidden\\\": 64, \\\"learning_rate\\\": 0.07660676721573413, \\\"dropout\\\": 0.2278440588743216}\", \"_aml_system_HD_b8ab1926-a58a-4f61-ac15-0b7a0c9d3aa6_1\": \"{\\\"hidden\\\": 128, \\\"learning_rate\\\": 0.024225515091124184, \\\"dropout\\\": 0.00477652879088919}\", \"HD_b8ab1926-a58a-4f61-ac15-0b7a0c9d3aa6_1\": \"{\\\"hidden\\\": 128, \\\"learning_rate\\\": 0.024225515091124184, \\\"dropout\\\": 0.00477652879088919}\", \"_aml_system_HD_b8ab1926-a58a-4f61-ac15-0b7a0c9d3aa6_2\": \"{\\\"hidden\\\": 128, \\\"learning_rate\\\": 0.04774940841142156, \\\"dropout\\\": 0.01232807734831523}\", \"HD_b8ab1926-a58a-4f61-ac15-0b7a0c9d3aa6_2\": \"{\\\"hidden\\\": 128, \\\"learning_rate\\\": 0.04774940841142156, \\\"dropout\\\": 0.01232807734831523}\", \"_aml_system_final_best_metric_update_retry_count\": \"1\", \"final_best_metric_update_retry_count\": \"1\"}, \"end_time_utc\": \"2021-08-12T17:23:29.609856Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/hyperdrive.txt\": \"https://filesharedevacme.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_b8ab1926-a58a-4f61-ac15-0b7a0c9d3aa6/azureml-logs/hyperdrive.txt?sv=2019-07-07&sr=b&sig=9QvGtbKiYNl3mrwgB5RoKNiYXTcUBzFx%2BqitYmEDTCk%3D&st=2021-08-12T18%3A13%3A45Z&se=2021-08-13T02%3A23%3A45Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/hyperdrive.txt\"]], \"run_duration\": \"0:29:03\", \"run_number\": \"862\", \"run_queued_details\": {\"status\": \"Completed\", \"details\": null}, \"hyper_parameters\": {\"hidden\": [\"choice\", [[32, 64, 128]]], \"learning_rate\": [\"uniform\", [0.001, 0.1]], \"dropout\": [\"uniform\", [0, 0.25]]}}, \"child_runs\": [{\"run_id\": \"HD_b8ab1926-a58a-4f61-ac15-0b7a0c9d3aa6_0\", \"run_number\": 863, \"metric\": 0.00032466, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-08-12T17:18:29.892801Z\", \"end_time\": \"2021-08-12T17:22:35.984766Z\", \"created_time\": \"2021-08-12T16:54:57.430735Z\", \"created_time_dt\": \"2021-08-12T16:54:57.430735Z\", \"duration\": \"0:27:38\", \"hyperdrive_id\": \"b8ab1926-a58a-4f61-ac15-0b7a0c9d3aa6\", \"arguments\": null, \"param_hidden\": 64, \"param_learning_rate\": 0.07660676721573413, \"param_dropout\": 0.2278440588743216, \"best_metric\": 0.00032466}, {\"run_id\": \"HD_b8ab1926-a58a-4f61-ac15-0b7a0c9d3aa6_1\", \"run_number\": 864, \"metric\": 0.00042603, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-08-12T17:18:30.110495Z\", \"end_time\": \"2021-08-12T17:22:17.277648Z\", \"created_time\": \"2021-08-12T16:54:57.436264Z\", \"created_time_dt\": \"2021-08-12T16:54:57.436264Z\", \"duration\": \"0:27:19\", \"hyperdrive_id\": \"b8ab1926-a58a-4f61-ac15-0b7a0c9d3aa6\", \"arguments\": null, \"param_hidden\": 128, \"param_learning_rate\": 0.024225515091124184, \"param_dropout\": 0.00477652879088919, \"best_metric\": 0.00032466}, {\"run_id\": \"HD_b8ab1926-a58a-4f61-ac15-0b7a0c9d3aa6_2\", \"run_number\": 865, \"metric\": 0.0003363, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-08-12T17:18:30.300068Z\", \"end_time\": \"2021-08-12T17:22:31.254654Z\", \"created_time\": \"2021-08-12T16:54:57.43552Z\", \"created_time_dt\": \"2021-08-12T16:54:57.43552Z\", \"duration\": \"0:27:33\", \"hyperdrive_id\": \"b8ab1926-a58a-4f61-ac15-0b7a0c9d3aa6\", \"arguments\": null, \"param_hidden\": 128, \"param_learning_rate\": 0.04774940841142156, \"param_dropout\": 0.01232807734831523, \"best_metric\": 0.00032466}], \"children_metrics\": {\"categories\": [0], \"series\": {\"Hidden Layers\": [{\"categories\": [863, 864, 865], \"mode\": \"markers\", \"name\": \"Hidden Layers\", \"stepped\": false, \"type\": \"scatter\", \"data\": [64, 128, 128]}, {\"categories\": [863, 864, 865], \"mode\": \"lines\", \"name\": \"Hidden Layers_min\", \"stepped\": true, \"type\": \"scatter\", \"data\": [64, 64, 64]}], \"Learning Rate\": [{\"categories\": [863, 864, 865], \"mode\": \"markers\", \"name\": \"Learning Rate\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.07660676721573413, 0.024225515091124184, 0.04774940841142156]}, {\"categories\": [863, 864, 865], \"mode\": \"lines\", \"name\": \"Learning Rate_min\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.07660676721573413, 0.024225515091124184, 0.024225515091124184]}], \"Dropout\": [{\"categories\": [863, 864, 865], \"mode\": \"markers\", \"name\": \"Dropout\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.2278440588743216, 0.00477652879088919, 0.01232807734831523]}, {\"categories\": [863, 864, 865], \"mode\": \"lines\", \"name\": \"Dropout_min\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.2278440588743216, 0.00477652879088919, 0.00477652879088919]}], \"Loss\": [{\"categories\": [863, 864, 865], \"mode\": \"markers\", \"name\": \"Loss\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.001230738591402769, 0.0007607795996591449, 0.0004199444956611842]}, {\"categories\": [863, 864, 865], \"mode\": \"lines\", \"name\": \"Loss_min\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.001230738591402769, 0.0007607795996591449, 0.0004199444956611842]}], \"Root Mean Squared Error\": [{\"categories\": [863, 864, 865], \"mode\": \"markers\", \"name\": \"Root Mean Squared Error\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.00032465814729221165, 0.0004260325222276151, 0.0003362952556926757]}, {\"categories\": [863, 864, 865], \"mode\": \"lines\", \"name\": \"Root Mean Squared Error_min\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.00032465814729221165, 0.00032465814729221165, 0.00032465814729221165]}], \"Mean Absolute Error\": [{\"categories\": [863, 864, 865], \"mode\": \"markers\", \"name\": \"Mean Absolute Error\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.018018271774053574, 0.020640555769205093, 0.01833835430443287]}, {\"categories\": [863, 864, 865], \"mode\": \"lines\", \"name\": \"Mean Absolute Error_min\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.018018271774053574, 0.018018271774053574, 0.018018271774053574]}], \"Mean Absolute Percentage Error\": [{\"categories\": [863, 864, 865], \"mode\": \"markers\", \"name\": \"Mean Absolute Percentage Error\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.012798110023140907, 0.01657709851861, 0.0160599984228611]}, {\"categories\": [863, 864, 865], \"mode\": \"lines\", \"name\": \"Mean Absolute Percentage Error_min\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.012798110023140907, 0.012798110023140907, 0.012798110023140907]}]}, \"metricName\": null, \"primaryMetricName\": \"Root Mean Squared Error\", \"showLegend\": false}, \"run_metrics\": [{\"name\": \"best_child_by_primary_metric\", \"run_id\": \"HD_b8ab1926-a58a-4f61-ac15-0b7a0c9d3aa6\", \"categories\": [0], \"series\": [{\"data\": [{\"metric_name\": [\"Root Mean Squared Error\", \"Root Mean Squared Error\", \"Root Mean Squared Error\"], \"timestamp\": [\"2021-08-12 17:22:26.936220+00:00\", \"2021-08-12 17:22:57.669895+00:00\", \"2021-08-12 17:22:57.669895+00:00\"], \"run_id\": [\"HD_b8ab1926-a58a-4f61-ac15-0b7a0c9d3aa6_1\", \"HD_b8ab1926-a58a-4f61-ac15-0b7a0c9d3aa6_0\", \"HD_b8ab1926-a58a-4f61-ac15-0b7a0c9d3aa6_0\"], \"metric_value\": [0.0004260325222276151, 0.00032465814729221165, 0.00032465814729221165], \"final\": [false, false, true]}]}]}], \"run_logs\": \"[2021-08-12T16:54:26.355248][API][INFO]Experiment created\\r\\n[2021-08-12T16:54:26.845787][GENERATOR][INFO]Trying to sample '3' jobs from the hyperparameter space\\r\\n[2021-08-12T16:54:27.004184][GENERATOR][INFO]Successfully sampled '3' jobs, they will soon be submitted to the execution target.\\r\\n[2021-08-12T16:54:56.790557][GENERATOR][INFO]All jobs generated.\\r\\n[2021-08-12T16:54:56.8618846Z][SCHEDULER][INFO]Scheduling job, id='HD_b8ab1926-a58a-4f61-ac15-0b7a0c9d3aa6_0'\\r\\n[2021-08-12T16:54:56.687689][GENERATOR][INFO]Max number of jobs '3' reached for experiment.\\r\\n[2021-08-12T16:54:56.8643830Z][SCHEDULER][INFO]Scheduling job, id='HD_b8ab1926-a58a-4f61-ac15-0b7a0c9d3aa6_2'\\r\\n[2021-08-12T16:54:56.8629700Z][SCHEDULER][INFO]Scheduling job, id='HD_b8ab1926-a58a-4f61-ac15-0b7a0c9d3aa6_1'\\r\\n[2021-08-12T16:54:57.5042020Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_b8ab1926-a58a-4f61-ac15-0b7a0c9d3aa6_1'\\r\\n[2021-08-12T16:54:57.4954904Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_b8ab1926-a58a-4f61-ac15-0b7a0c9d3aa6_0'\\r\\n[2021-08-12T16:54:58.5228530Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_b8ab1926-a58a-4f61-ac15-0b7a0c9d3aa6_2'\\r\\n[2021-08-12T17:23:29.761436][CONTROLLER][INFO]Experiment was 'ExperimentStatus.RUNNING', is 'ExperimentStatus.FINISHED'.\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.31.0\"}, \"loading\": false}"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RunId: HD_b8ab1926-a58a-4f61-ac15-0b7a0c9d3aa6\n",
            "Web View: https://ml.azure.com/runs/HD_b8ab1926-a58a-4f61-ac15-0b7a0c9d3aa6?wsid=/subscriptions/ac401033-05b1-43d5-a5ea-e5dcb9c75b49/resourcegroups/rg-devtest-databricks-01/workspaces/ml-devtest&tid=fa1a69b7-9b39-4cb7-8701-41985a92e9bb\n",
            "\n",
            "Streaming azureml-logs/hyperdrive.txt\n",
            "=====================================\n",
            "\n",
            "\"<START>[2021-08-12T16:54:26.355248][API][INFO]Experiment created<END>\\n\"\"<START>[2021-08-12T16:54:26.845787][GENERATOR][INFO]Trying to sample '3' jobs from the hyperparameter space<END>\\n\"\"<START>[2021-08-12T16:54:27.004184][GENERATOR][INFO]Successfully sampled '3' jobs, they will soon be submitted to the execution target.<END>\\n\"\n",
            "\n",
            "Execution Summary\n",
            "=================\n",
            "RunId: HD_b8ab1926-a58a-4f61-ac15-0b7a0c9d3aa6\n",
            "Web View: https://ml.azure.com/runs/HD_b8ab1926-a58a-4f61-ac15-0b7a0c9d3aa6?wsid=/subscriptions/ac401033-05b1-43d5-a5ea-e5dcb9c75b49/resourcegroups/rg-devtest-databricks-01/workspaces/ml-devtest&tid=fa1a69b7-9b39-4cb7-8701-41985a92e9bb\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "{'runId': 'HD_b8ab1926-a58a-4f61-ac15-0b7a0c9d3aa6',\n 'target': 'capstone-compute',\n 'status': 'Completed',\n 'startTimeUtc': '2021-08-12T16:54:25.993769Z',\n 'endTimeUtc': '2021-08-12T17:23:29.609856Z',\n 'properties': {'primary_metric_config': '{\"name\": \"Root Mean Squared Error\", \"goal\": \"minimize\"}',\n  'resume_from': 'null',\n  'runTemplate': 'HyperDrive',\n  'azureml.runsource': 'hyperdrive',\n  'platform': 'AML',\n  'ContentSnapshotId': '9d56e277-31a7-4c4a-bb7a-408d302bae05',\n  'user_agent': 'python/3.6.9 (Linux-5.4.0-1051-azure-x86_64-with-debian-buster-sid) msrest/0.6.21 Hyperdrive.Service/1.0.0 Hyperdrive.SDK/core.1.31.0',\n  'score': '0.00032465814729221165',\n  'best_child_run_id': 'HD_b8ab1926-a58a-4f61-ac15-0b7a0c9d3aa6_0',\n  'best_metric_status': 'Succeeded'},\n 'inputDatasets': [],\n 'outputDatasets': [],\n 'logFiles': {'azureml-logs/hyperdrive.txt': 'https://filesharedevacme.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_b8ab1926-a58a-4f61-ac15-0b7a0c9d3aa6/azureml-logs/hyperdrive.txt?sv=2019-07-07&sr=b&sig=cqhUXhDiACNSbWIhXkrXh7c%2FkmP5FMpoUlv1TY0gvv4%3D&st=2021-08-12T17%3A13%3A39Z&se=2021-08-13T01%3A23%3A39Z&sp=r'},\n 'submittedBy': 'Taylor Bluth'}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1628789065043
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Model\n",
        "\n",
        "TODO: In the cell below, get the best model from the hyperdrive experiments and display all the properties of the model."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Get your best run and save the model from that run.\n",
        "best_hyperdrive_run = hyperdrive_run.get_best_run_by_primary_metric()\n",
        "print(best_hyperdrive_run.get_metrics())\n",
        "print(best_hyperdrive_run.get_details())\n",
        "print(best_hyperdrive_run.get_file_names())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Hidden Layers': 64, 'Learning Rate': 0.07660676721573413, 'Dropout': 0.2278440588743216, 'Loss': [0.001230738591402769, 0.0006518422742374241, 0.00033820437965914607, 0.00041763816261664033, 0.00043919330346398056, 0.00021037731494288892, 0.00019562695524655282, 0.00015243361121974885, 0.0001557858195155859, 0.00024802624830044806, 0.00024056479742284864, 0.0005595794063992798, 0.00041389241232536733, 0.00013434875290840864, 0.0003993867721874267, 0.00013915121962781996, 0.00013301461876835674, 0.00018744953558780253, 0.0003734350320883095, 0.00014216764247976243, 0.00018310117593500763, 0.0003222002414986491, 0.000132048488012515, 0.00016786168271210045, 0.00032465814729221165], 'Root Mean Squared Error': 0.00032465814729221165, 'Mean Absolute Error': 0.018018271774053574, 'Mean Absolute Percentage Error': 0.012798110023140907, 'ETH_keras': 'aml://artifactId/ExperimentRun/dcid.HD_b8ab1926-a58a-4f61-ac15-0b7a0c9d3aa6_0/ETH_keras_1628788924.png'}\n",
            "{'runId': 'HD_b8ab1926-a58a-4f61-ac15-0b7a0c9d3aa6_0', 'target': 'capstone-compute', 'status': 'Completed', 'startTimeUtc': '2021-08-12T17:18:29.892801Z', 'endTimeUtc': '2021-08-12T17:22:35.984766Z', 'properties': {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': '9d56e277-31a7-4c4a-bb7a-408d302bae05', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json', 'azureml.RuntimeType': 'Hosttools'}, 'inputDatasets': [{'dataset': {'id': '0cb8b2aa-aedf-45f6-b7d6-fc86b399984a'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'crypto', 'mechanism': 'Direct'}}, {'dataset': {'id': '0cb8b2aa-aedf-45f6-b7d6-fc86b399984a'}, 'consumptionDetails': {'type': 'Reference'}}], 'outputDatasets': [], 'runDefinition': {'script': 'crypto_train.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--input_data', 'DatasetConsumptionConfig:crypto', '--hidden', '64', '--learning_rate', '0.07660676721573413', '--dropout', '0.2278440588743216'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'capstone-compute', 'dataReferences': {}, 'data': {'crypto': {'dataLocation': {'dataset': {'id': '0cb8b2aa-aedf-45f6-b7d6-fc86b399984a', 'name': None, 'version': None}, 'dataPath': None, 'uri': None}, 'mechanism': 'Direct', 'environmentVariableName': 'crypto', 'pathOnCompute': None, 'overwrite': False}}, 'outputData': {}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': 2592000, 'nodeCount': 1, 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'tensorflow-keras-sklearn-training', 'version': '5', 'python': {'interpreterPath': 'python', 'userManagedDependencies': True, 'condaDependencies': {'name': 'project_environment', 'dependencies': ['python=3.6.2', {'pip': ['azureml-defaults']}], 'channels': ['anaconda', 'conda-forge']}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': None, 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': \"\\nFROM mcr.microsoft.com/azureml/openmpi4.1.0-cuda11.0.3-cudnn8-ubuntu18.04:20210615.v1\\n\\nENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/tensorflow-2.4\\n\\n# Create conda environment\\nRUN conda create -p $AZUREML_CONDA_ENVIRONMENT_PATH \\\\\\n    python=3.7 pip=20.2.4\\n\\n# Prepend path to AzureML conda environment\\nENV PATH $AZUREML_CONDA_ENVIRONMENT_PATH/bin:$PATH\\n\\n# Install pip dependencies\\nRUN HOROVOD_WITH_TENSORFLOW=1 \\\\\\n    pip install 'matplotlib>=3.3,<3.4' \\\\\\n                'psutil>=5.8,<5.9' \\\\\\n                'tqdm>=4.59,<4.60' \\\\\\n                'pandas>=1.1,<1.2' \\\\\\n                'scipy>=1.5,<1.6' \\\\\\n                'numpy>=1.10,<1.20' \\\\\\n                'azureml-core==1.30.0' \\\\\\n                'azureml-defaults==1.30.0' \\\\\\n                'azureml-telemetry==1.30.0' \\\\\\n                'tensorboard==2.4.0' \\\\\\n                'tensorflow-gpu==2.4.1' \\\\\\n                'horovod[tensorflow-gpu]==0.21.3' \\\\\\n                'scikit-learn==0.24.0'\\n\\n# This is needed for mpi to locate libpython\\nENV LD_LIBRARY_PATH $AZUREML_CONDA_ENVIRONMENT_PATH/lib:$LD_LIBRARY_PATH\\n\", 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': None}, 'aiSuperComputer': {'instanceType': None, 'imageVersion': None, 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'enableAzmlInt': True, 'priority': None, 'slaTier': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}, 'parameters': []}, 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://filesharedevacme.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_b8ab1926-a58a-4f61-ac15-0b7a0c9d3aa6_0/azureml-logs/20_image_build_log.txt?sv=2019-07-07&sr=b&sig=CRmAZNCOzxAOX4KL1XHNLaiCD8SlEbQhPj8AD3FOvDs%3D&st=2021-08-12T17%3A14%3A28Z&se=2021-08-13T01%3A24%3A28Z&sp=r', 'azureml-logs/55_azureml-execution-tvmps_a6919d4b07f0e29a767184134e44df25cf5b944a920325045f4c68a2407d5711_p.txt': 'https://filesharedevacme.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_b8ab1926-a58a-4f61-ac15-0b7a0c9d3aa6_0/azureml-logs/55_azureml-execution-tvmps_a6919d4b07f0e29a767184134e44df25cf5b944a920325045f4c68a2407d5711_p.txt?sv=2019-07-07&sr=b&sig=AzMcsMULQEvBwdV0o1axan%2BIgFnyL7ffhSbUoZtP8e4%3D&st=2021-08-12T17%3A14%3A28Z&se=2021-08-13T01%3A24%3A28Z&sp=r', 'azureml-logs/65_job_prep-tvmps_a6919d4b07f0e29a767184134e44df25cf5b944a920325045f4c68a2407d5711_p.txt': 'https://filesharedevacme.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_b8ab1926-a58a-4f61-ac15-0b7a0c9d3aa6_0/azureml-logs/65_job_prep-tvmps_a6919d4b07f0e29a767184134e44df25cf5b944a920325045f4c68a2407d5711_p.txt?sv=2019-07-07&sr=b&sig=GbaH7W%2BtoHiXq4PdAFmuRGYCq5F7PnJy1HXjYGihQak%3D&st=2021-08-12T17%3A14%3A28Z&se=2021-08-13T01%3A24%3A28Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://filesharedevacme.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_b8ab1926-a58a-4f61-ac15-0b7a0c9d3aa6_0/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=YDhXUohg%2FXDDrd5OVBtHEoPek%2BOCJPf3bzeWgri6vo0%3D&st=2021-08-12T17%3A14%3A28Z&se=2021-08-13T01%3A24%3A28Z&sp=r', 'azureml-logs/75_job_post-tvmps_a6919d4b07f0e29a767184134e44df25cf5b944a920325045f4c68a2407d5711_p.txt': 'https://filesharedevacme.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_b8ab1926-a58a-4f61-ac15-0b7a0c9d3aa6_0/azureml-logs/75_job_post-tvmps_a6919d4b07f0e29a767184134e44df25cf5b944a920325045f4c68a2407d5711_p.txt?sv=2019-07-07&sr=b&sig=QYkrL4O91ZDUNpQM5B35r5Qgx5bEQ%2Bhrs%2BCUg7o8ing%3D&st=2021-08-12T17%3A14%3A28Z&se=2021-08-13T01%3A24%3A28Z&sp=r', 'azureml-logs/process_info.json': 'https://filesharedevacme.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_b8ab1926-a58a-4f61-ac15-0b7a0c9d3aa6_0/azureml-logs/process_info.json?sv=2019-07-07&sr=b&sig=o%2BJEJNiNiHKHFqneeHUgT%2F7D%2BYnZ1UKsUCqugtv4IDs%3D&st=2021-08-12T17%3A14%3A28Z&se=2021-08-13T01%3A24%3A28Z&sp=r', 'azureml-logs/process_status.json': 'https://filesharedevacme.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_b8ab1926-a58a-4f61-ac15-0b7a0c9d3aa6_0/azureml-logs/process_status.json?sv=2019-07-07&sr=b&sig=OXTsSY3CgwtRkUjCSF0YXZRKhfeeA16URryd5h%2BKuwM%3D&st=2021-08-12T17%3A14%3A28Z&se=2021-08-13T01%3A24%3A28Z&sp=r', 'logs/azureml/93_azureml.log': 'https://filesharedevacme.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_b8ab1926-a58a-4f61-ac15-0b7a0c9d3aa6_0/logs/azureml/93_azureml.log?sv=2019-07-07&sr=b&sig=%2BIrS3ORRKo7aOPIwYNfNOiqD%2B1XZY2rrBWKvGGGl074%3D&st=2021-08-12T17%3A14%3A28Z&se=2021-08-13T01%3A24%3A28Z&sp=r', 'logs/azureml/dataprep/backgroundProcess.log': 'https://filesharedevacme.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_b8ab1926-a58a-4f61-ac15-0b7a0c9d3aa6_0/logs/azureml/dataprep/backgroundProcess.log?sv=2019-07-07&sr=b&sig=CcwfiJwSmQEOCo1vfKSR2SCMODCa8H%2Bui3eBpkX1WLM%3D&st=2021-08-12T17%3A14%3A28Z&se=2021-08-13T01%3A24%3A28Z&sp=r', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://filesharedevacme.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_b8ab1926-a58a-4f61-ac15-0b7a0c9d3aa6_0/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-07-07&sr=b&sig=eg5hN4774b0CTs5%2Bg4qo9RLycU1%2B0KRiqa9yJ%2BfDClU%3D&st=2021-08-12T17%3A14%3A28Z&se=2021-08-13T01%3A24%3A28Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://filesharedevacme.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_b8ab1926-a58a-4f61-ac15-0b7a0c9d3aa6_0/logs/azureml/job_prep_azureml.log?sv=2019-07-07&sr=b&sig=mF%2Ba4xBS6PSfnKiUK45NHciHPVFhw67gTyrMmNr4uJU%3D&st=2021-08-12T17%3A14%3A28Z&se=2021-08-13T01%3A24%3A28Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://filesharedevacme.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_b8ab1926-a58a-4f61-ac15-0b7a0c9d3aa6_0/logs/azureml/job_release_azureml.log?sv=2019-07-07&sr=b&sig=otad6%2FdT8JyCH%2Ffm7vYCkzos6f5Cdfx8A4W12LXDKCA%3D&st=2021-08-12T17%3A14%3A28Z&se=2021-08-13T01%3A24%3A28Z&sp=r'}, 'submittedBy': 'Taylor Bluth'}\n",
            "['ETH_keras_1628788924.png', 'azureml-logs/20_image_build_log.txt', 'azureml-logs/55_azureml-execution-tvmps_a6919d4b07f0e29a767184134e44df25cf5b944a920325045f4c68a2407d5711_p.txt', 'azureml-logs/65_job_prep-tvmps_a6919d4b07f0e29a767184134e44df25cf5b944a920325045f4c68a2407d5711_p.txt', 'azureml-logs/70_driver_log.txt', 'azureml-logs/75_job_post-tvmps_a6919d4b07f0e29a767184134e44df25cf5b944a920325045f4c68a2407d5711_p.txt', 'azureml-logs/process_info.json', 'azureml-logs/process_status.json', 'logs/azureml/93_azureml.log', 'logs/azureml/dataprep/backgroundProcess.log', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log', 'logs/azureml/job_prep_azureml.log', 'logs/azureml/job_release_azureml.log', 'outputs/ETH_hyperdrive_model/saved_model.pb', 'outputs/ETH_hyperdrive_model/variables/variables.data-00000-of-00001', 'outputs/ETH_hyperdrive_model/variables/variables.index', 'outputs/X_test.npy', 'outputs/X_train.npy', 'outputs/scaler.joblib', 'outputs/y_test.npy', 'outputs/y_train.npy']\n"
          ]
        }
      ],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1628789068849
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # create a model folder in the current directory\r\n",
        "# os.makedirs('./hyperdrive_model', exist_ok=True)\r\n",
        "\r\n",
        "# best_hyperdrive_run.download_files(output_directory='./hyperdrive_model')\r\n",
        "\r\n",
        "# import tensorflow\r\n",
        "# print('Tensorflow version', tensorflow.__version__)\r\n",
        "# from tensorflow.keras.models import load_model\r\n",
        "# import joblib\r\n",
        "\r\n",
        "# model = load_model('hyperdrive_model/outputs/ETH_hyperdrive_model') # this doesn't work because the single node compute has a different version of tensorflow (v2.1) than the cluster compute (v2.4)\r\n",
        "\r\n",
        "# # make prediction\r\n",
        "# X_train = np.load('hyperdrive_model/X_train.npy')\r\n",
        "# y_train = np.load('hyperdrive_model/y_train.npy')\r\n",
        "# X_test = np.load('hyperdrive_model/X_test.npy')\r\n",
        "# y_test = np.load('hyperdrive_model/y_test.npy')\r\n",
        "# # joblib.load('hyperdrive_model/scaler.joblib') # not yet needed\r\n",
        "# y_hat = model.predict(X_test)\r\n",
        "\r\n",
        "# model.evaluate(X_train, y_train)\r\n",
        "# model.evaluate(X_test, y_test)"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628790064379
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the best model\n",
        "best_hyperdrive_run.register_model(model_name = 'hyperdrive_Ethereum_price_forecast', model_path='./outputs')"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 21,
          "data": {
            "text/plain": "Model(workspace=Workspace.create(name='ml-devtest', subscription_id='ac401033-05b1-43d5-a5ea-e5dcb9c75b49', resource_group='rg-devtest-databricks-01'), name=hyperdrive_Ethereum_price_forecast, id=hyperdrive_Ethereum_price_forecast:4, version=4, tags={}, properties={})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1628790537855
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}